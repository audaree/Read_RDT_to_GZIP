{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "#using CurveFit\n",
    "using Dates, DataFrames\n",
    "#, Distributions, DSP\n",
    "#using Gtk\n",
    "#using LaTeXStrings\n",
    "using NativeFileDialog\n",
    "using Plots\n",
    "using Printf\n",
    "#using Tk\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n",
    "\n",
    "# Select a Datawell daily .RDT file\n",
    "infil = pick_file(\"C:\\\\\", filterlist=\"*RDT\");\n",
    "##infil = \"G:\\\\Wave_data\\\\Card Data\\\\mooloolaba\\\\Mooloolaba_WR_2018-2020\\\\07039ALO.RDT\"\n",
    "println(\"Selected \",infil)\n",
    "\n",
    "#Change the type-interpretation of the binary file data to unsigned integer\n",
    "println(\"Reading BINARY data from \",infil)\n",
    "data_array = reinterpret(UInt8, read(infil));\n",
    "\n",
    "date_time_list = []\n",
    "north_hex_values = []\n",
    "\n",
    "ii = 1\n",
    "RDT_df = DataFrame([[],[],[],[],[],[]], [\"Date\", \"UTC\", \"Heave\", \"North\", \"West\", \"GPS_error\"])\n",
    "\n",
    "# Convert df column types from 'Any' to their proper type\n",
    "RDT_df.Date = map(DateTime, RDT_df.Date);\n",
    "RDT_df.UTC = map(DateTime, RDT_df.UTC);\n",
    "RDT_df.Heave = map(Float64, RDT_df.Heave);\n",
    "RDT_df.North = map(Float64, RDT_df.North);\n",
    "RDT_df.West = map(Float64, RDT_df.West);\n",
    "RDT_df.GPS_error = map(Int32, RDT_df.GPS_error);\n",
    " \n",
    "\n",
    "println(\"Decoding RDT data now\")\n",
    "flush(stdout)\n",
    "\n",
    "while ii < length(data_array)\n",
    "    \n",
    "    start_of_message = string(data_array[ii], base=16, pad=2)\n",
    "    message_id = string(data_array[ii+1], base=16, pad=2)\n",
    "    message_length = parse(Int, string(data_array[ii+2], base=16, pad=2) * string(data_array[ii+3], base=16, pad=2), base= 16)\n",
    "    check_sum1 = string(data_array[ii+4], base=16, pad=2)    \n",
    "\n",
    "    yr = parse(Int,(string(data_array[ii+5], base=16) * string(data_array[ii+6], base=16, pad=2)), base= 16)\n",
    "\n",
    "    month = parse(Int, string(data_array[ii+7], base=16, pad=2), base= 16)\n",
    "    day = parse(Int, string(data_array[ii+8], base=16, pad=2), base= 16)\n",
    "    hour = parse(Int, string(data_array[ii+9], base=16, pad=2), base= 16)\n",
    "    minute = parse(Int, string(data_array[ii+10], base=16, pad=2), base= 16)\n",
    "\n",
    "    # Calculate the sample rate\n",
    "    sample_rate_hex = parse(UInt32,\"0x\"* string(data_array[ii+11], base=16, pad=2) * string(data_array[ii+12], base=16, pad=2) \n",
    "        * string(data_array[ii+13], base=16, pad=2) * string(data_array[ii+14], base=16, pad=2))\n",
    "    sample_rate = reinterpret(Float32, parse(UInt32, \"0x\"*string(sample_rate_hex, base=16)))\n",
    "\n",
    "    utc = DateTime(yr,month,day,hour,minute)\n",
    "    aest = utc + Hour(10)\n",
    "    push!(date_time_list,aest)\n",
    "\n",
    "    if (sample_rate != 1.28f0) \n",
    "\n",
    "        println(\"Error: Sample rate not 1.28 Hz - Program terminated!\")\n",
    "        quit()\n",
    "\n",
    "    end\n",
    "\n",
    "#==\n",
    "    println(\"Start of message = \",start_of_message)\n",
    "    println(\"Message Id = \",message_id)\n",
    "    println(\"Message length = \",message_length)\n",
    "    println(\"Checksum = \",check_sum1)\n",
    "    println(\"Date/Time (UTC) = \",utc)\n",
    "    println(\"Sample rate = \",sample_rate,\" Hz.\")\n",
    "==#    \n",
    "    rows = (message_length-10)/6\n",
    "    \n",
    "    for jj in 15:6:message_length\n",
    "    \n",
    "        # generate an array of dates at spacing equal to sample_rate\n",
    "        aest = utc .+ Hour(10)\n",
    "\n",
    "        heave = []\n",
    "        north = []\n",
    "        west = []\n",
    "\n",
    "        # Calculate the displacements\n",
    "        heave_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj], base=16, pad=2) * string(data_array[ii+jj+1], base=16, pad=2))\n",
    "        heave = reinterpret(Int16, parse(UInt16, \"0x\"*string(heave_hex, base=16))) / 100\n",
    "\n",
    "        global north_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj+2], base=16, pad=2) * string(data_array[ii+jj+3], base=16, pad=2))\n",
    "        north = reinterpret(Int16, parse(UInt16, \"0x\"*string(north_hex, base=16))) / 100\n",
    "\n",
    "        west_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj+4], base=16, pad=2) * string(data_array[ii+jj+5], base=16, pad=2))\n",
    "        west = reinterpret(Int16, parse(UInt16, \"0x\"*string(west_hex, base=16))) / 100\n",
    "\n",
    "        push!(RDT_df,(utc .+ Hour(10), utc, heave, north, west, parse(Int, last(string(north_hex, base=2, pad=16),1))))\n",
    "         \n",
    "        # increment the record time\n",
    "        utc = utc + Microsecond.(1/sample_rate * 1000000)\n",
    "\n",
    "    end\n",
    "    \n",
    "    check_sum2 = string(data_array[message_length+1], base=16, pad=2)\n",
    "    print(\".\")\n",
    "    flush(stdout)\n",
    "#==\n",
    "    println(\"Checksum = \",check_sum2)\n",
    "    println(\"_________________________________________\")\n",
    "==#\n",
    "    \n",
    "    ii += message_length + 6\n",
    "    \n",
    "end\n",
    "\n",
    "# print number of GPS errors if they exist\n",
    "gps_error_number = sum(RDT_df.GPS_error)\n",
    "if gps_error_number > 0\n",
    "    global gps_error_locations = findall(RDT_df.GPS_error .> 0)\n",
    "    println(\"\\nAlert: there were \",gps_error_number,\" errors in this record!\\n\")\n",
    "    flush(stdout)\n",
    "end\n",
    "\n",
    "println(\"\\nPreparing plot now...This takes a while!\")\n",
    "flush(stdout)\n",
    "\n",
    "#==\n",
    "# Plot all data over entire period\n",
    "p1 = plot(RDT_df.Date,RDT_df.Heave, color=:blue, lw=:0.5, alpha=:0.5, title=\"Heave\", label=\"\")\n",
    "if gps_error_number > 0\n",
    "    heave_label = string(gps_error_number)*\" GPS Errors\"\n",
    "    p1 = vline!(RDT_df.Date[gps_error_locations], alpha=:1, label=heave_label,lw=0.25, lc=:red)\n",
    "end\n",
    "\n",
    "p2 = plot(RDT_df.Date,RDT_df.North, color=:green, lw=:0.5, alpha=:0.5, title=\"North\", label=\"\")\n",
    "p3 = plot(RDT_df.Date,RDT_df.West, color=:red, title=\"West\", label=\"\")\n",
    "\n",
    "# create the date/time ticks for x-axis\n",
    "tm_tick = range(first(RDT_df.UTC),last(RDT_df.Date),step=Hour(12))\n",
    "ticks = Dates.format.(tm_tick,\"dd/mm HH:MM\")\n",
    "\n",
    "rdt_plot = plot(p1, p2, p3, layout=(3,1), size=(1600,800),\n",
    "    lw=:0.5,\n",
    "    xlim=(first(RDT_df.UTC),last(RDT_df.Date)), xticks=(tm_tick,ticks), xtickfontsize=7,ytickfontsize=8, xminorticks=12,\n",
    "    framestyle = :box,fg_legend=:transparent, bg_legend=:transparent, legend=:bottomleft,\n",
    "    plot_title = Dates.format(date_time_list[1], \"dd/mm/yy HH:MM\")*\" to \"*Dates.format(date_time_list[end], \"dd/mm/yy HH:MM\"), plot_titlefontsize=:12, titlefontsize=:10,\n",
    "    leftmargin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n",
    "\n",
    "flname = \".\\\\Plot_\"*last(split(infil, \"\\\\\"))*\".png\"\n",
    "savefig(flname)\n",
    "\n",
    "display(rdt_plot)\n",
    "==#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_record = DateTime(2009,05,10,6,0)\n",
    "next_record = start_record + Minute(60)\n",
    "jj = findall(start_record .<= RDT_df.Date .< next_record)\n",
    "heave = RDT_df.Heave[jj]\n",
    "timestamps = start_record .+ Microsecond.(collect(0:length(RDT_df.Heave[jj])-1) / 1.28 * 1000000)\n",
    "\n",
    "tm_tick = range(first(timestamps),last(timestamps),step=Minute(5))\n",
    "ticks = Dates.format.(tm_tick,\"MM:SS\")\n",
    "\n",
    "\n",
    "plot(timestamps, heave, size=(1200,400), xlims=(timestamps[1],timestamps[end]), xticks=(tm_tick,ticks), ylims=(-2,2), framestyle = :box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all .RDT files in selected directory to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDT_df.Date[jj[begin]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, CurveFit\n",
    "using NativeFileDialog\n",
    "using Glob\n",
    "using Dates, DataFrames, Distributions, DSP\n",
    "using LaTeXStrings\n",
    "using Printf, Polynomials\n",
    "using Statistics #, StatsPlotss\n",
    "using StatsBase\n",
    "\n",
    "function fix_gps_errors(heave, date, gps_flag)\n",
    "# function to apply polynomial fit to WSE's affected by GPS errors\n",
    "# uses selectable offset value to fine-tune result\n",
    "#####################################\n",
    "\n",
    "    gps_errors = findall(x -> x == 1, gps_flag)\n",
    "    heave_length = length(heave)\n",
    "    \n",
    "    if !isempty(gps_errors)\n",
    "        \n",
    "        println(length(gps_errors),\" GPS errors at \", Dates.format.(date, \"yyyy-mm-dd HH:MM\"))\n",
    "        \n",
    "        for ii ∈ reverse(gps_errors)\n",
    "\n",
    "            error_center = ii\n",
    "\n",
    "            # User-selected offset either side of GPS error\n",
    "            lower_offset = upper_offset = 120\n",
    "\n",
    "            if error_center <= lower_offset\n",
    "                lower_offset = error_center - 1\n",
    "            end\n",
    "\n",
    "            if error_center+upper_offset > heave_length\n",
    "                upper_offset = heave_length - error_center\n",
    "            end\n",
    "\n",
    "            # Ensure there are at least 3 points for fitting\n",
    "            lower_offset = max(lower_offset, 2)\n",
    "            upper_offset = max(upper_offset, 2)\n",
    "    \n",
    "            # Fit curve to subset of heave before GPS error\n",
    "            left_side_points = error_center-lower_offset:error_center\n",
    "            fit1 = curve_fit(Polynomial, left_side_points, heave[left_side_points], 2)\n",
    "            yfit1 = fit1.(left_side_points)\n",
    "            yfit1[length(yfit1)] = 0.0\n",
    "\n",
    "            # Fit curve to subset of heave after GPS error\n",
    "            right_side_points = error_center:error_center+upper_offset\n",
    "            fit2 = curve_fit(Polynomial, right_side_points, heave[right_side_points], 2)\n",
    "            yfit2 = fit2.(right_side_points)\n",
    "            yfit2[1] = 0.0\n",
    "\n",
    "            # apply polynomial results to wse's on both sides of GPS error\n",
    "            heave[left_side_points] .= heave[left_side_points] - yfit1\n",
    "            heave[right_side_points] .= heave[right_side_points] - yfit2\n",
    "            heave[ii] = 0.0    # set wse at GPS error location to 0\n",
    "\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    return(heave)\n",
    "    \n",
    "    end     # fix_gps_errors()\n",
    "\n",
    "\n",
    "# smooth the spectra into bands centered on 0.05Hz spacing (i.e. 0:0.005:0.64)\n",
    "function smooth_spectra(Pden_in, sample_frequency)\n",
    "##################################################\n",
    "\n",
    "    nyquist = sample_frequency/2\n",
    "\n",
    "    freq_in = range(0, stop=nyquist, length=length(Pden_in))\n",
    "\n",
    "    freq_out = [0.0]\n",
    "    Pden_smoothed = [mean(Pden_in[1:8])]\n",
    "\n",
    "    i = 9\n",
    "    while i <= length(Pden_in)\n",
    "\n",
    "        push!(freq_out,freq_in[i+8])\n",
    "\n",
    "        if i < length(Pden_in)-16\n",
    "\n",
    "            push!(Pden_smoothed, mean(Pden_in[i:i+16]))\n",
    "\n",
    "        end\n",
    "\n",
    "        i+=16\n",
    "\n",
    "    end\n",
    "\n",
    "    push!(Pden_smoothed, mean(Pden_in[end-8:end]))\n",
    "            \n",
    "    return (freq_out, Pden_smoothed)\n",
    "        \n",
    "end    # smooth_spectra()\n",
    "\n",
    "\n",
    "function get_Fourier_coefficients(heave, north, west, sample_frequency)\n",
    "#####################################################    \n",
    "\n",
    "    # Get the cross periodograms\n",
    "    cps_heave_heave = mt_cross_power_spectra([heave heave]', fs=sample_frequency);\n",
    "    cps_north_north = mt_cross_power_spectra([north north]', fs=sample_frequency);\n",
    "    cps_west_west = mt_cross_power_spectra([west west]', fs=sample_frequency);\n",
    "\n",
    "    cps_north_heave = mt_cross_power_spectra([north heave]', fs=sample_frequency);\n",
    "    cps_west_heave = mt_cross_power_spectra([west heave]', fs=sample_frequency);\n",
    "    cps_north_west = mt_cross_power_spectra([north west]', fs=sample_frequency);\n",
    "\n",
    "##    fhh = cps_heave_heave.freq\n",
    "    fhh, Chh = smooth_spectra(real.(cps_heave_heave.power[1,1,:]), sample_frequency)\n",
    "\n",
    "    #fnn = cps_north_north.freq\n",
    "    fhh, Cnn = smooth_spectra(real.(cps_north_north.power[1,1,:]), sample_frequency)\n",
    "\n",
    "    #fww = cps_west_west.freq\n",
    "    fhh, Cww = smooth_spectra(real.(cps_west_west.power[1,1,:]), sample_frequency)\n",
    "\n",
    "    #fnw = cps_north_west.freq\n",
    "    fhh, Cnw = smooth_spectra(real.(cps_north_west.power[1,2,:]), sample_frequency)\n",
    "\n",
    "    #fnh = cps_north_heave.freq\n",
    "    fhh, Qnh = smooth_spectra(imag.(cps_north_heave.power[1,2,:]), sample_frequency)\n",
    "\n",
    "    #fwh = cps_west_heave.freq\n",
    "    fhh, Qwh = smooth_spectra(imag.(cps_west_heave.power[1,2,:]), sample_frequency)\n",
    "\n",
    "    a1 = Qnh ./ ((Cnn .+ Cww) .* Chh) .^ 0.5\n",
    "    b1 = -Qwh ./ ((Cnn .+ Cww) .* Chh) .^ 0.5\n",
    "\n",
    "    a2 = (Cnn .- Cww) ./ (Cnn .+ Cww)\n",
    "    b2 = -2 .* Cnw ./ (Cnn .+ Cww)\n",
    "    \n",
    "    return(fhh, Chh, a1, b1, a2, b2)\n",
    "    \n",
    "end    # get_Fourier_coefficients()\n",
    "\n",
    "\n",
    "function calc_f2_Pden2(heave, sample_frequency)\n",
    "#############################\n",
    "    \n",
    "    # Show spectra using Welch's method to better define bimodal events\n",
    "    ps_w = welch_pgram(heave, 256, 128; onesided=true, nfft=256, fs=sample_frequency, window=hanning);\n",
    "    f2 = freq(ps_w);\n",
    "    Pden2 = power(ps_w)    \n",
    "\n",
    "    return(f2, Pden2)\n",
    "\n",
    "end    # calc_f2_Pden2()\n",
    "    \n",
    "\n",
    "function calc_spread_direction(a1,b1)\n",
    "#####################################\n",
    "    \n",
    "    θ₀ = atan.(b1,a1)\n",
    "    m1 = (a1.^2 .+ b1.^2).^0.5\n",
    "##    m2 = a2.*cos.(2*θ₀) .+ b2.*sin.(2*θ₀)\n",
    "##    n2 = -a2.*sin.(2*θ₀) .+ b2.*cos.(2*θ₀)\n",
    "\n",
    "    # Calculate the spread\n",
    "    σc = (2 .* (1 .- m1)).^0.5;\n",
    "\n",
    "    direction = mod.(rad2deg.(atan.(b1,a1)),360)\n",
    "\n",
    "    return(σc, direction)\n",
    "\n",
    "end    # calc_spread_direction()\n",
    "\n",
    "\n",
    "# Function to read binary file\n",
    "function read_binary_file(filename)\n",
    "###################################\n",
    "\n",
    "    open(filename, \"r\") do file\n",
    "        return(read(file))\n",
    "    end\n",
    "\n",
    "end    # read_binary_file()\n",
    "\n",
    "\n",
    "# Function to find all header indices\n",
    "function find_headers(data, header)\n",
    "###################################\n",
    "\n",
    "    header_indices = []\n",
    "    header_length = length(header)\n",
    "    data_length = length(data)\n",
    "    \n",
    "    for i in 1:(data_length - header_length + 1)\n",
    "        if data[i:i+header_length-1] == header\n",
    "            push!(header_indices, i)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return(header_indices)\n",
    "\n",
    "end    # find_headers()\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "#######################################################################################################\n",
    "#######################################################################################################\n",
    "\n",
    "# Define the path to the directory you want to search in\n",
    "directory_path = pick_folder()\n",
    "\n",
    "# Use glob to find all .HXV files in the directory and subdirectories\n",
    "rdt_files = glob(\".//*.RDT\", directory_path)\n",
    "rdt_files = rdt_files[1:end-1]    # remove the file named TMP.RDT\n",
    "\n",
    "# build df containing displacements and Fourier coefficients for selected day\n",
    "global displacement_df = DataFrame(\n",
    "    Date = DateTime[], \n",
    "    Heave = Vector{Float64}[], \n",
    "    North = Vector{Float64}[], \n",
    "    West = Vector{Float64}[], \n",
    "    fhh = Vector{Float64}[], \n",
    "    Chh = Vector{Float64}[], \n",
    "    a1 = Vector{Float64}[], \n",
    "    b1 = Vector{Float64}[], \n",
    "    a2 = Vector{Float64}[], \n",
    "    b2 = Vector{Float64}[], \n",
    "    f2 = Vector{Float64}[], \n",
    "    Pden2 = Vector{Float64}[], \n",
    "    Spread = Vector{Float64}[], \n",
    "    Direction = Vector{Float64}[]\n",
    ")\n",
    "\n",
    "for infil ∈ rdt_files\n",
    "\n",
    "    println(\"Reading BINARY data from \",infil)\n",
    "    data_array = reinterpret(UInt8, read(infil))\n",
    "    \n",
    "    date_time_list = []\n",
    "    north_hex_values = []\n",
    "    \n",
    "    ii = 1\n",
    "       \n",
    "    while ii < length(data_array)\n",
    "        \n",
    "        start_of_message = string(data_array[ii], base=16, pad=2)\n",
    "        message_id = string(data_array[ii+1], base=16, pad=2)\n",
    "        message_length = parse(Int, string(data_array[ii+2], base=16, pad=2) * string(data_array[ii+3], base=16, pad=2), base= 16)\n",
    "        check_sum1 = string(data_array[ii+4], base=16, pad=2)    \n",
    "    \n",
    "        yr = parse(Int,(string(data_array[ii+5], base=16) * string(data_array[ii+6], base=16, pad=2)), base= 16)\n",
    "    \n",
    "        month = parse(Int, string(data_array[ii+7], base=16, pad=2), base= 16)\n",
    "        day = parse(Int, string(data_array[ii+8], base=16, pad=2), base= 16)\n",
    "        hour = parse(Int, string(data_array[ii+9], base=16, pad=2), base= 16)\n",
    "        minute = parse(Int, string(data_array[ii+10], base=16, pad=2), base= 16)\n",
    "    \n",
    "        # Calculate the sample rate\n",
    "        sample_rate_hex = parse(UInt32,\"0x\"* string(data_array[ii+11], base=16, pad=2) * string(data_array[ii+12], base=16, pad=2) \n",
    "            * string(data_array[ii+13], base=16, pad=2) * string(data_array[ii+14], base=16, pad=2))\n",
    "        sample_frequency = reinterpret(Float32, parse(UInt32, \"0x\"*string(sample_rate_hex, base=16)))\n",
    "    \n",
    "        utc = DateTime(yr,month,day,hour,minute)\n",
    "        aest = utc + Hour(10)\n",
    "        push!(date_time_list,aest)\n",
    "    \n",
    "        if (sample_frequency != 1.28f0) \n",
    "    \n",
    "            println(\"Error: Sample rate not 1.28 Hz - Program terminated!\")\n",
    "            quit()\n",
    "    \n",
    "        end\n",
    "    \n",
    "    #==\n",
    "        println(\"Start of message = \",start_of_message)\n",
    "        println(\"Message Id = \",message_id)\n",
    "        println(\"Message length = \",message_length)\n",
    "        println(\"Checksum = \",check_sum1)\n",
    "        println(\"Date/Time (UTC) = \",utc)\n",
    "        println(\"Sample rate = \",sample_rate,\" Hz.\")\n",
    "    ==#    \n",
    "        rows = (message_length-10)/6\n",
    "        global heave = Float64[]; north = Float64[]; west = Float64[]; gps_flag = []\n",
    "        \n",
    "        for jj ∈ 15:6:message_length\n",
    "        \n",
    "            # generate an array of dates at spacing equal to sample_rate\n",
    "            aest = utc .+ Hour(10)\n",
    "       \n",
    "            # Calculate the displacements\n",
    "            heave_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj], base=16, pad=2) * string(data_array[ii+jj+1], base=16, pad=2))\n",
    "            push!(heave, reinterpret(Int16, parse(UInt16, \"0x\"*string(heave_hex, base=16))) / 100)\n",
    "    \n",
    "            north_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj+2], base=16, pad=2) * string(data_array[ii+jj+3], base=16, pad=2))\n",
    "            push!(north, reinterpret(Int16, parse(UInt16, \"0x\"*string(north_hex, base=16))) / 100)\n",
    "    \n",
    "            west_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj+4], base=16, pad=2) * string(data_array[ii+jj+5], base=16, pad=2))\n",
    "            push!(west, reinterpret(Int16, parse(UInt16, \"0x\"*string(west_hex, base=16))) / 100)\n",
    "    \n",
    "            # identify GPS error flags\n",
    "            if parse(Int, last(string(north_hex, base=2, pad=16),1)) != 0\n",
    "                push!(gps_flag,1)\n",
    "            else\n",
    "                push!(gps_flag,0)\n",
    "            end\n",
    "\n",
    "        end\n",
    "        \n",
    "        if sum(gps_flag) > 0\n",
    "            heave = fix_gps_errors(heave, utc, gps_flag)\n",
    "        end\n",
    "    \n",
    "        # get frequencies, spectra, and Fourier coefficients\n",
    "        fhh, Chh, a1, b1, a2, b2 = get_Fourier_coefficients(heave, north, west, sample_frequency)\n",
    "    \n",
    "        f2, Pden2 = calc_f2_Pden2(heave, sample_frequency)\n",
    "        σc, direction = calc_spread_direction(a1,b1)\n",
    "    \n",
    "        push!(displacement_df, (aest, heave, north, west, fhh, Chh, a1, b1, a2, b2, f2, Pden2, σc, direction))\n",
    "\n",
    "        check_sum2 = string(data_array[message_length+1], base=16, pad=2)\n",
    "        ii += message_length + 6\n",
    "        \n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "# Sort the df by date ascending\n",
    "sort!(displacement_df, :Date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort!(displacement_df, :Date)\n",
    "#Plots.plot(RDT_df.Date, RDT_df.Heave, label=\"\", size=(1800,800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Seralize to save df to .bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CodecZlib, Serialization, DataFrames\n",
    "using NativeFileDialog\n",
    "using CSV\n",
    "using Glob\n",
    "using Dates, DataFrames, Distributions, DSP\n",
    "using LaTeXStrings\n",
    "using Printf\n",
    "using Statistics #, StatsPlotss\n",
    "using StatsBase\n",
    "\n",
    "# Serialize the DataFrame to a file\n",
    "outfil = \".\\\\Data\\\\\" * split(directory_path,\"\\\\\")[end-1]*\"_\"*Dates.format(Date(Date(displacement_df.Date[1])), \"yyyy-mm-dd\")*\n",
    "    \"_to_\"*Dates.format(Date(Date(displacement_df.Date[end])), \"yyyy-mm-dd\")*\".bin\"\n",
    "\n",
    "println(\"Writing binary-formatted data to \",outfil)\n",
    "flush(stdout)\n",
    "\n",
    "@time begin\n",
    "\n",
    "    open(outfil, \"w\") do io\n",
    "        serialize(io, displacement_df)\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Serialize to read gzipped .bin file to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CodecZlib, Serialization, DataFrames\n",
    "using NativeFileDialog\n",
    "using CSV\n",
    "using Glob\n",
    "using Dates, DataFrames, Distributions, DSP\n",
    "using LaTeXStrings\n",
    "using Printf\n",
    "using Statistics #, StatsPlotss\n",
    "using StatsBase\n",
    "\n",
    "##include(\"../Split_Spectra/Split_Spectra_Tools.jl\")\n",
    "##include(\"C://Users//PC1//Julia_programs//Split_Spectra//Split_Spectra_Tools.jl\")\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n",
    "\n",
    "const sample_frequency = 1.28\n",
    "\n",
    "function read_gzip_file(io)\n",
    "###########################\n",
    "    \n",
    "    gz = GzipDecompressorStream(io)                # Create a Gzip decompressor stream\n",
    "    deserialized_displacement_df = deserialize(gz) # Deserialize the DataFrame from the decompressed stream\n",
    "    close(gz)                                      # Close the decompressor stream\n",
    "    \n",
    "    return(deserialized_displacement_df)\n",
    "    \n",
    "end    # read_gzip_file()\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "#######################################################################################################\n",
    "#######################################################################################################\n",
    "\n",
    "\n",
    "# Select the binary file\n",
    "infil = pick_file(\"C:\\\\Users\\\\PC1\\\\Julia_programs\\\\Datawell\\\\Read_RDT\\\\Data\\\\\", filterlist=\"*bin\")\n",
    "\n",
    "println(\"Selected \", infil)\n",
    "\n",
    "@time begin\n",
    "    \n",
    "    # Deserialize the DataFrame from the file\n",
    "    displacement_df = open(read_gzip_file, infil, \"r\")\n",
    "    \n",
    "end\n",
    "\n",
    "# Verify the contents\n",
    "##println(displacement_df)\n",
    "\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use this for reading Noise_Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infil = \"C:\\\\Users\\\\PC1\\\\Julia_programs\\\\Datawell\\\\Read_RDT\\\\Data\\\\Noise_floor.bin\"\n",
    "println(\"Reading Noise Floor data from \",infil)\n",
    "flush(stdout)\n",
    "\n",
    "@time begin\n",
    "    \n",
    "    # Deserialize the DataFrame from the file\n",
    "    noise_floors_df = open(read_gzip_file, infil, \"r\");\n",
    "    \n",
    "end\n",
    "\n",
    "# Verify the contents\n",
    "##println(noise_floors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Dates\n",
    "\n",
    "# Step 1: Create the new DataFrame `records_df`\n",
    "records_df = DataFrame(Date = DateTime[], Heave = Vector{Float64}[], North = Vector{Float64}[], West = Vector{Float64}[], GPS_error = Vector{Float64}[])\n",
    "\n",
    "# Helper function to create 30-minute intervals\n",
    "function create_intervals(df::DataFrame)\n",
    "    intervals = []\n",
    "    start_time = minimum(df.Date)\n",
    "    end_time = maximum(df.Date)\n",
    "    while start_time <= end_time\n",
    "        push!(intervals, (start_time, start_time + Minute(30)))\n",
    "        start_time += Minute(30)\n",
    "    end\n",
    "    return intervals\n",
    "end\n",
    "\n",
    "# Step 2: Iterate over the `may_2009_df` DataFrame, grouping data into 30-minute intervals\n",
    "intervals = create_intervals(may_2009_df)\n",
    "\n",
    "for (start_time, end_time) in intervals\n",
    "    # Filter the data for the current 30-minute interval\n",
    "    mask = (may_2009_df.Date .>= start_time) .& (may_2009_df.Date .< end_time)\n",
    "    interval_df = may_2009_df[mask, :]\n",
    "\n",
    "    if nrow(interval_df) > 0\n",
    "        # Extract data for the columns\n",
    "        heave_values = interval_df.Heave\n",
    "        north_values = interval_df.North\n",
    "        west_values = interval_df.West\n",
    "        gps_errors_values = interval_df.GPS_error\n",
    "\n",
    "        # Step 3: Populate the `records_df` DataFrame\n",
    "        push!(records_df, (start_time, heave_values, north_values, west_values, gps_errors_values))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Display the first few rows to verify\n",
    "first(records_df, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "p1 = Plots.plot(records_df.Heave[1])\n",
    "p1 = Plots.plot!(records_df.North[1])\n",
    "\n",
    "p1_plot = plot(p1, leftmargin = 15Plots.mm, bottommargin = 15Plots.mm, grid=true, size=(1800,800), gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, colorbar=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate GPS errors in .RDT directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using Dates, DataFrames\n",
    "using NativeFileDialog\n",
    "using Printf\n",
    "\n",
    "error_df = DataFrame([[],[]],[\"Date\", \"GPS_errors\"])\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n",
    "\n",
    "rdt_directory = pick_folder()\n",
    "\n",
    "# build list of all rdt files in selected directory\n",
    "rdt_files = filter(x->occursin(\".RDT\",x), readdir(rdt_directory));\n",
    "rdt_files = rdt_files[findall(x->endswith(uppercase(x), \".RDT\"), rdt_files)];\n",
    "\n",
    "for jj in rdt_files\n",
    "    \n",
    "    if jj != \"TMP.RDT\"\n",
    "    \n",
    "        infil = rdt_directory * \"\\\\\" * jj\n",
    "    \n",
    "    end\n",
    "    \n",
    "##    println(infil)\n",
    "    print('.')\n",
    "    \n",
    "    data_array = reinterpret(UInt8, read(infil));\n",
    "\n",
    "    ii = 1\n",
    "    \n",
    "    while ii < length(data_array)\n",
    "\n",
    "        gps_error_sum = 0\n",
    "\n",
    "        start_of_message = string(data_array[ii], base=16, pad=2)\n",
    "        message_id = string(data_array[ii+1], base=16, pad=2)\n",
    "        message_length = parse(Int, string(data_array[ii+2], base=16, pad=2) * string(data_array[ii+3], base=16, pad=2), base= 16)\n",
    "        check_sum1 = string(data_array[ii+4], base=16, pad=2)    \n",
    "\n",
    "        yr = parse(Int,(string(data_array[ii+5], base=16) * string(data_array[ii+6], base=16, pad=2)), base= 16)\n",
    "\n",
    "        month = parse(Int, string(data_array[ii+7], base=16, pad=2), base= 16)\n",
    "        day = parse(Int, string(data_array[ii+8], base=16, pad=2), base= 16)\n",
    "        hour = parse(Int, string(data_array[ii+9], base=16, pad=2), base= 16)\n",
    "        minute = parse(Int, string(data_array[ii+10], base=16, pad=2), base= 16)\n",
    "\n",
    "        utc = DateTime(yr,month,day,hour,minute)\n",
    "        aest = utc + Hour(10)\n",
    "\n",
    "        for jj in 15:6:message_length\n",
    "\n",
    "            gps_error_sum += parse(Int, last(string(parse(UInt16,\"0x\"* string(data_array[ii+jj+2], base=16, pad=2) * string(data_array[ii+jj+3], base=16, pad=2)), base=2, pad=16),1))\n",
    "        end\n",
    "\n",
    "        check_sum2 = string(data_array[message_length+1], base=16, pad=2)\n",
    "        ii += message_length + 6\n",
    "\n",
    "        if gps_error_sum > 0\n",
    "#            println(aest,' ',gps_error_sum)\n",
    "            push!(error_df,(aest,gps_error_sum))\n",
    "        end\n",
    "\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "# sort the df on dates        \n",
    "error_df = sort(error_df, [order(:Date, rev=false)])\n",
    "\n",
    "\n",
    "# create the date/time ticks for x-axis\n",
    "tm_tick = range(first(error_df.Date), last(error_df.Date), step=Month(1))\n",
    "ticks = Dates.format.(tm_tick,\"mm-yy\")\n",
    "\n",
    "b1 = bar(error_df.Date, error_df.GPS_errors, lc=:blue, lw=:0.5, xrotation=90, size=(1800,500), \n",
    "    xlim=(first(error_df.Date),last(error_df.Date)), xticks=(tm_tick,ticks), xtickfontsize=7, ytickfontsize=12,\n",
    "    ylim=(0,60), yminorticks=4, ylabel=\"No. errors\",\n",
    "    title=\"Daily GPS errors - \" * (splitpath(rdt_directory))[end] * \"\\n\\n\" * Dates.format(first(error_df.Date), \"dd/mm/yy\") * \" to \" * Dates.format(last(error_df.Date), \"dd/mm/yy\"),\n",
    "    leftmargin = 15Plots.mm, bottommargin = 25Plots.mm,\n",
    "    grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, legend=false)\n",
    "\n",
    "b1_plot = plot(b1)\n",
    "\n",
    "flname = \".\\\\Plot_\"*splitpath(rdt_directory)[end]\n",
    "\n",
    "csv_file = flname*\".csv\"\n",
    "plt_file = flname*\".png\"\n",
    "\n",
    "CSV.write(csv_file, error_df)\n",
    "savefig(plt_file)\n",
    "\n",
    "display(b1_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **********************************************************************************************************************\n",
    "## All below is Noise Floor code\n",
    "# **********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore possibility of sorting RDT files by stat().mtime - unfortunately, only works with recent files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates, DataFrames\n",
    "using NativeFileDialog\n",
    "using Printf\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n",
    "\n",
    "# select directory\n",
    "rdt_directory = pick_folder()\n",
    "\n",
    "# build list of all csv files in selected directory\n",
    "rdt_files = filter(x->occursin(\".RDT\",x), readdir(rdt_directory));\n",
    "\n",
    "a = []; b = []\n",
    "for ii in (rdt_files)\n",
    "    push!(a,ii)\n",
    "    push!(b,Dates.unix2datetime.(mtime.(joinpath.(rdt_directory,ii))))\n",
    "end\n",
    "\n",
    "c = [a b]\n",
    "\n",
    "c[sortperm(c[:,2]),:]\n",
    "\n",
    "# Convert the array to a DataFrame\n",
    "df = DataFrame(c, [:Event, :Date])\n",
    "\n",
    "# Convert the Date column to Date type\n",
    "#df.Date = Date.(df.Date, \"yyyy-mm-dd HH:MM:SS\")\n",
    "\n",
    "# Sort the DataFrame by Date column\n",
    "sorted_df = sort(df, :Date)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "println(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract the binary data from HEX files to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates, DataFrames\n",
    "using NativeFileDialog\n",
    "using Printf\n",
    "\n",
    "# Function to parse a date from hex values\n",
    "function parse_date(data_array, index)\n",
    "######################################    \n",
    "    \n",
    "    yr = parse(Int, string(data_array[index], base=16) * string(data_array[index + 1], base=16, pad=2), base=16)\n",
    "    month = parse(Int, string(data_array[index + 2], base=16, pad=2), base=16)\n",
    "    day = parse(Int, string(data_array[index + 3], base=16, pad=2), base=16)\n",
    "    hour = parse(Int, string(data_array[index + 4], base=16, pad=2), base=16)\n",
    "    minute = parse(Int, string(data_array[index + 5], base=16, pad=2), base=16)\n",
    "    \n",
    "    return(DateTime(yr, month, day, hour, minute))\n",
    "    \n",
    "end    # parse_date()\n",
    "\n",
    "\n",
    "# Function to parse sample rate\n",
    "function parse_sample_rate(data_array, index)\n",
    "#############################################\n",
    "    \n",
    "    sample_rate_hex = parse(UInt32, \"0x\" * string(data_array[index], base=16, pad=2) *\n",
    "        string(data_array[index + 1], base=16, pad=2) * string(data_array[index + 2], base=16, pad=2) *\n",
    "        string(data_array[index + 3], base=16, pad=2))\n",
    "    \n",
    "    return(reinterpret(Float32, sample_rate_hex))\n",
    "\n",
    "end    # parse_sample_rate()\n",
    "\n",
    "\n",
    "# Function to parse displacement values\n",
    "function parse_displacement(data_array, index)\n",
    "##############################################\n",
    "    \n",
    "    hex_value = parse(UInt16, \"0x\" * string(data_array[index], base=16, pad=2) * string(data_array[index + 1], base=16, pad=2))\n",
    "    \n",
    "    return(reinterpret(Int16, hex_value) / 100)\n",
    "    \n",
    "end    # parse_displacement()\n",
    "\n",
    "# Set the range of dates to be processed\n",
    "\n",
    "# Hay Point MV Spartia long wave event\n",
    "start_date = Date(\"01-05-2009\", \"dd-mm-yyyy\") - Day(3)\n",
    "end_date = Date(\"01-06-2009\", \"dd-mm-yyyy\") + Day(3)\n",
    "\n",
    "# Hay Point DWR-G buoy on shore - used to calculate Noise Floor\n",
    "##start_date = Date(\"15-02-2018\", \"dd-mm-yyyy\") - Day(3)\n",
    "##end_date = Date(\"01-05-2018\", \"dd-mm-yyyy\") + Day(3)\n",
    "\n",
    "# QGHL DWR-G calibration\n",
    "##start_date = Date(\"09-10-2023\", \"dd-mm-yyyy\") - Day(3)\n",
    "##end_date = Date(\"14-12-2024\", \"dd-mm-yyyy\") + Day(3)\n",
    "\n",
    "mask = (start_date .< sorted_df.Date .<= end_date)\n",
    "infils = sorted_df[mask, :].Event\n",
    "\n",
    "##infils=sorted_df.Event\n",
    "# Create a DataFrame with specified column types\n",
    "RDT_df = DataFrame(\n",
    "    Date = DateTime[], \n",
    "    UTC = DateTime[], \n",
    "    Heave = Float64[], \n",
    "    North = Float64[], \n",
    "    West = Float64[], \n",
    "    GPS_error = Int[]\n",
    ")\n",
    "\n",
    "for infil in infils\n",
    "    \n",
    "    fil = rdt_directory * \"\\\\\" * infil\n",
    "    println(fil)\n",
    "    \n",
    "    # Read the binary data from the file\n",
    "    data_array = reinterpret(UInt8, read(fil))\n",
    "    \n",
    "    ii = 1\n",
    "    \n",
    "    while ii < length(data_array)\n",
    "        \n",
    "        message_length = parse(Int, string(data_array[ii + 2], base=16, pad=2) * string(data_array[ii + 3], base=16, pad=2), base=16)\n",
    "        \n",
    "        utc = parse_date(data_array, ii + 5)\n",
    "        aest = utc + Hour(10)\n",
    "        sample_rate = parse_sample_rate(data_array, ii + 11)\n",
    "        \n",
    "        if sample_rate != 1.28f0\n",
    "            \n",
    "            println(\"Error: Sample rate not 1.28 Hz - Program terminated!\")\n",
    "            quit()\n",
    "            \n",
    "        end\n",
    "        \n",
    "        for jj in 15:6:message_length\n",
    "            \n",
    "            heave = parse_displacement(data_array, ii + jj)\n",
    "            north = parse_displacement(data_array, ii + jj + 2)\n",
    "            gps_error = parse(UInt16, \"0x\" * string(data_array[ii + jj + 3], base=16, pad=2)) & 1\n",
    "            west = parse_displacement(data_array, ii + jj + 4)\n",
    "            \n",
    "            push!(RDT_df, (aest, utc, heave, north, west, gps_error))\n",
    "            utc += Microsecond(1 / sample_rate * 1e6)\n",
    "            \n",
    "        end\n",
    "        \n",
    "        ii += message_length + 6\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "println(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert sequential df to df of 30-minute rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new DataFrame `records_df`\n",
    "records_df = DataFrame(Date = DateTime[], Heave = Vector{Float64}[], North = Vector{Float64}[], West = Vector{Float64}[], GPS_error = Vector{Float64}[])\n",
    "\n",
    "# Helper function to create 30-minute intervals\n",
    "function create_intervals(df::DataFrame)\n",
    "########################################\n",
    "    \n",
    "    intervals = []\n",
    "    # Set the range of dates to be processed\n",
    "    start_time = DateTime.(\"01-05-2009 00:00\", \"dd-mm-yyyy HH:MM\")\n",
    "    end_time = DateTime.(\"01-06-2009 00:00\", \"dd-mm-yyyy HH:MM\")\n",
    "\n",
    "# Noise floor dates\n",
    "##    start_time = DateTime(\"01-02-2018 00:00\", \"dd-mm-yyyy HH:MM\")\n",
    "##    end_time = DateTime(\"01-05-2018 00:00\", \"dd-mm-yyyy HH:MM\")\n",
    "\n",
    "##    start_time = DateTime(\"09-11-2023 00:00\", \"dd-mm-yyyy HH:MM\")\n",
    "##    end_time = DateTime(\"15-11-2023 00:00\", \"dd-mm-yyyy HH:MM\")\n",
    "\n",
    "\n",
    "    while start_time <= end_time\n",
    "        push!(intervals, (start_time, start_time + Minute(30)))\n",
    "        start_time += Minute(30)\n",
    "    end\n",
    "    \n",
    "    return(intervals)\n",
    "    \n",
    "end    # create_intervals()\n",
    "\n",
    "\n",
    "# Iterate over the DataFrame, grouping data into 30-minute intervals\n",
    "intervals = create_intervals(RDT_df)\n",
    "\n",
    "for (start_time, end_time) in intervals\n",
    "    \n",
    "    # Filter the data for the current 30-minute interval\n",
    "    mask = (RDT_df.Date .>= start_time) .& (RDT_df.Date .< end_time)\n",
    "    interval_df = RDT_df[mask, :]\n",
    "\n",
    "    if nrow(interval_df) > 0\n",
    "        \n",
    "        # Extract data for the columns\n",
    "        heave_values = interval_df.Heave\n",
    "        north_values = interval_df.North\n",
    "        west_values = interval_df.West\n",
    "        gps_errors_values = interval_df.GPS_error\n",
    "\n",
    "        # Step 3: Populate the `records_df` DataFrame\n",
    "        push!(records_df, (start_time, heave_values, north_values, west_values, gps_errors_values))\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "println(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CurveFit\n",
    "\n",
    "# Function to check if there's at least one '1' in the array\n",
    "function has_one(records_df::DataFrame, row_index::Int)\n",
    "#######################################################\n",
    "    \n",
    "    return any(records_df.GPS_error[row_index] .== 1)\n",
    "    \n",
    "end    # has_one()\n",
    "    \n",
    "\n",
    "# function to apply polynomial fit to WSE's affected by GPS errors\n",
    "function fix_gps_errors(index, df)  \n",
    "# uses selectable offset value to fine-tune result\n",
    "    \n",
    "    # locate GPS errors\n",
    "    global gps_errors = findall(x -> x == 1, df.GPS_error[index])\n",
    "    \n",
    "    if !isempty(gps_errors)\n",
    "        \n",
    "        heave = df.Heave[index]\n",
    "        \n",
    "        for ii ∈ reverse(gps_errors[3:end])\n",
    "\n",
    "            error_center = ii\n",
    "\n",
    "            # User-selected offset either side of GPS error\n",
    "            lower_offset = upper_offset = 120\n",
    "\n",
    "            if error_center <= lower_offset\n",
    "                lower_offset = error_center - 1\n",
    "            end\n",
    "\n",
    "            if error_center+upper_offset > 2304\n",
    "                upper_offset = 2304 - error_center\n",
    "            end\n",
    "\n",
    "            # Fit curve to subset of heave before GPS error\n",
    "            left_side_points = error_center-lower_offset:error_center\n",
    "            fit1 = curve_fit(Polynomial, left_side_points, heave[left_side_points], 2)\n",
    "            yfit1 = fit1.(left_side_points)\n",
    "            yfit1[length(yfit1)] = 0.0\n",
    "\n",
    "            # Fit curve to subset of heave after GPS error\n",
    "            right_side_points = error_center:error_center+upper_offset\n",
    "            fit2 = curve_fit(Polynomial, right_side_points, heave[right_side_points], 2)\n",
    "            yfit2 = fit2.(right_side_points)\n",
    "            yfit2[1] = 0.0\n",
    "\n",
    "            # apply polynomial results to wse's on both sides of GPS error\n",
    "            heave[left_side_points] .= heave[left_side_points] - yfit1\n",
    "            heave[right_side_points] .= heave[right_side_points] - yfit2\n",
    "            heave[ii] = 0.0    # set wse at GPS error location to 0\n",
    "\n",
    "        end\n",
    "    \n",
    "    end\n",
    "    \n",
    "    return(heave)\n",
    "    \n",
    "end     # fix_gps_errors()\n",
    "\n",
    "records_df.Fixed_Heave = records_df.Heave\n",
    "\n",
    "# Check each row in records_df\n",
    "for row_index in 1:nrow(records_df)\n",
    "    \n",
    "    if has_one(records_df, row_index)\n",
    "        \n",
    "        records_df.Fixed_Heave[row_index] = fix_gps_errors(row_index, records_df)\n",
    "        \n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Spectra for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DSP\n",
    "using DataFrames\n",
    "\n",
    "# Sample frequency\n",
    "Fs = 1.28\n",
    "\n",
    "# Function to compute Welch's power spectral density\n",
    "function compute_welch_psd(heave_data, Fs)\n",
    "##########################################\n",
    "    \n",
    "    ps_w = welch_pgram(heave_data, 512, 256; onesided=true, nfft=512, fs=Fs, window=hanning)\n",
    "    freqs = freq(ps_w)\n",
    "    spectra = power(ps_w)\n",
    "    \n",
    "    return(freqs, spectra)\n",
    "    \n",
    "end    # compute_welch_psd()\n",
    "\n",
    "# Preallocate arrays\n",
    "num_rows = nrow(records_df)\n",
    "\n",
    "f2 = Vector{Vector{Float64}}(undef, num_rows)\n",
    "Pden2 = Vector{Vector{Float64}}(undef, num_rows)\n",
    "\n",
    "# Iterate over records_df and compute PSD\n",
    "for i in 1:num_rows\n",
    "    \n",
    "    print(\".\")\n",
    "    heave_data = records_df.Heave[i]\n",
    "    freqs, spectra = compute_welch_psd(heave_data, Fs)\n",
    "    \n",
    "    f2[i] = freqs\n",
    "    Pden2[i] = spectra\n",
    "    \n",
    "end\n",
    "\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the corrected spectra"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n",
    "\n",
    "using Plots\n",
    "\n",
    "p1 = Plots.plot()\n",
    "\n",
    "for ii in 1:length(f2)\n",
    "\n",
    "    p1 = Plots.plot!(f2[ii],Pden2[ii],label=\"\")\n",
    "\n",
    "end\n",
    "\n",
    "plot_p1 = plot(p1, yaxis=:log,\n",
    "    size = (1800, 800), titlefontsize=10, framestyle = :box, fg_legend=:transparent, legend=:bottomleft,\n",
    "    leftmargin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n",
    "\n",
    "display(plot_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do spectrogram of corrected spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "gr()\n",
    "\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 80% !important; }</style>\"))\n",
    "\n",
    "dates = records_df.Date\n",
    "freqs = f2[1]\n",
    "spectra = hcat(Pden2...)\n",
    "\n",
    "max_spec = maximum(spectra)\n",
    "\n",
    "start_date =  first(dates)\n",
    "last_date = last(dates)\n",
    "\n",
    "# display plots to screen\n",
    "tm_tick = range(start_date,last_date,step=Day(1))\n",
    "ticks = Dates.format.(tm_tick,\"dd\")\n",
    "\n",
    "p1 = contourf(dates, freqs, spectra, lw=0.25, c=cgrad(:Spectral, rev=true), clims=(0,max_spec), levels=10, fill=true)\n",
    "# draw grid lines on plot\n",
    "for i in 0:0.1:0.6\n",
    "    hline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "end\n",
    "\n",
    "for i in start_date:Day(1):last_date\n",
    "    vline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "end\n",
    "\n",
    "#title = Dates.format(start_date, \"yyyy-mm-dd\") * \" to \" * Dates.format(last_date, \"yyyy-mm-dd\")\n",
    "title1 = uppercase(split(rdt_directory,\"\\\\\")[end-1])*\"_\"*monthname(dates[1])*\"_\"*string(year(dates[1]))\n",
    "plot_file = \".\\\\Plots\\\\\"*title1*\"_monthly_spectrogram.png\"\n",
    "\n",
    "p1_plot = plot(p1, xlabel=\"Date\", xlim=(start_date,last_date), xticks=(tm_tick,ticks), xtickfontsize=7,\n",
    "        ylabel=\"Frequency (Hz)\", ylim=(0,0.4), ytickfontsize=8, \n",
    "        title=title1, framestyle = :box,\n",
    "        leftmargin = 15Plots.mm, bottommargin = 15Plots.mm, grid=true, size=(1800,800), gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, colorbar=true)\n",
    "\n",
    "#==\n",
    "try\n",
    "                                                \n",
    "    savefig(plot_file)\n",
    "    println(\"\\nPlot file saved as \"*plot_file)\n",
    "\n",
    "catch\n",
    "\n",
    "    \"Alert: Plot not saved!\"\n",
    "\n",
    "end\n",
    "==#\n",
    "display(p1_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = records_df.Date\n",
    "\n",
    "# Initialize an empty array to store daily intervals\n",
    "dates_array = Date[]\n",
    "\n",
    "# Iterate through dates and extract dates at daily intervals\n",
    "for i in 1:length(dates)\n",
    "    if i == 1 || day(dates[i]) != day(dates[i-1])\n",
    "        push!(dates_array, dates[i])\n",
    "    end\n",
    "end\n",
    "\n",
    "using Tk\n",
    "\n",
    "dates_array = Dates.format.(dates_array, \"yyyy-mm-dd\")\n",
    "\n",
    "w = Toplevel(\"Select Start Date\", 235, 650)\n",
    "tcl(\"pack\", \"propagate\", w, false)\n",
    "f = Frame(w)\n",
    "pack(f, expand=true, fill=\"both\")\n",
    "\n",
    "f1 = Frame(f)\n",
    "lb = Treeview(f1, dates_array)\n",
    "\n",
    "scrollbars_add(f1, lb)\n",
    "pack(f1,  expand=true, fill=\"both\")\n",
    "\n",
    "tcl(\"ttk::style\", \"configure\", \"TButton\", foreground=\"blue\", font=\"arial 16 bold\")\n",
    "b = Tk.Button(f, \"Ok\")\n",
    "pack(b)\n",
    "\n",
    "println(\"Select a time from the menu!\")\n",
    "flush(stdout)\n",
    "\n",
    "bind(b, \"command\") do path\n",
    "                    \n",
    "    file_choice = get_value(lb);\n",
    "\n",
    "    global start_date = DateTime(file_choice[1])\n",
    "\n",
    "end\n",
    "\n",
    "println(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "gr()\n",
    "\n",
    "last_date = start_date + Day(5)\n",
    "# display plots to screen\n",
    "tm_tick = range(start_date,last_date,step=Hour(6))\n",
    "ticks = Dates.format.(tm_tick,\"dd HH:MM\")\n",
    "\n",
    "p5 = contourf(dates, freqs, spectra, lw=0.25, c=cgrad(:Spectral, rev=true), clims=(0,max_spec), levels=10, fill=true)\n",
    "\n",
    "# draw grid lines on plot\n",
    "for i in 0:0.1:0.6\n",
    "    hline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "end\n",
    "\n",
    "for i in start_date:Hour(6):last_date\n",
    "    vline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "end\n",
    "\n",
    "title = title1*\"_\"*Dates.format(start_date, \"yyyy-mm-dd HH:MM\") * \" to \" * Dates.format(last_date, \"yyyy-mm-dd HH:MM\")\n",
    "plt_file5 = \".\\\\Plots\\\\\"*title\n",
    "plt_file5 = replace(plt_file5, \":\" => \"\")\n",
    "plt_file5 = replace(plt_file5, \" \" => \"_\") * \"_5day_specrtogram.png\" \n",
    "    \n",
    "p5_plot = plot(p5, xlabel=\"Date\", xlim=(start_date,last_date), xticks=(tm_tick,ticks), xtickfontsize=7,\n",
    "        ylabel=\"Frequency (Hz)\", ylim=(0,0.4), ytickfontsize=8, \n",
    "        title=title, framestyle = :box,\n",
    "        leftmargin = 15Plots.mm, bottommargin = 15Plots.mm, grid=true, size=(1800,800), gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, colorbar=true)\n",
    "\n",
    "try\n",
    "                                                \n",
    "    savefig(plt_file5)\n",
    "    println(\"\\nPlot file saved as \"*plt_file5)\n",
    "\n",
    "catch\n",
    "\n",
    "    \"Alert: Plot not saved!\"\n",
    "\n",
    "end\n",
    "\n",
    "display(p5_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "\n",
    "RDT_noise = DataFrame(Dict(\"Frequency\" => f2, \"Spectra\" => Pden2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Statistics\n",
    "using FFTW\n",
    "\n",
    "# Define a function to calculate MAD for a 1D array\n",
    "function mad(arr)\n",
    "    med = median(arr)\n",
    "    mad_value = median(abs.(arr .- med))\n",
    "    return mad_value\n",
    "end\n",
    "\n",
    "# Define a function to calculate MAD for a matrix\n",
    "function mad_matrix(matrix; dims=1)\n",
    "    if dims == 1\n",
    "        return [mad(matrix[:, i]) for i in 1:size(matrix, 2)]\n",
    "    elseif dims == 2\n",
    "        return [mad(matrix[i, :]) for i in 1:size(matrix, 1)]\n",
    "    else\n",
    "        error(\"Unsupported dimension: $dims\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# Extract all spectral arrays from the DataFrame\n",
    "spectral_values = Pden2\n",
    "\n",
    "# Convert the list of arrays into a matrix where each row is a spectrum\n",
    "spectral_matrix = hcat(spectral_values...)'\n",
    "\n",
    "# Calculate the mean spectra (mean of each column) directly\n",
    "mean_spectra = mean(spectral_matrix, dims=1)\n",
    "mean_spectra_vector = vec(mean_spectra)\n",
    "\n",
    "# Calculate the median spectra (median of each column)\n",
    "median_spectra = median(spectral_matrix, dims=1)\n",
    "\n",
    "# Calculate the MAD (median absolute deviation) for each frequency\n",
    "mad_spectra = mad_matrix(spectral_matrix, dims=1)\n",
    "\n",
    "# Convert the results to vectors\n",
    "median_spectra_vector = vec(median_spectra)\n",
    "mad_spectra_vector = vec(mad_spectra)\n",
    "\n",
    "println(\"Mean Spectra: \", mean_spectra_vector)\n",
    "println(\"Median Spectra: \", median_spectra_vector)\n",
    "println(\"MAD Spectra: \", mad_spectra_vector)\n",
    "\n",
    "# Define a function to remove outliers using MAD\n",
    "function remove_outliers_using_mad(matrix, threshold=3.0)\n",
    "    median_vals = median(matrix, dims=1)\n",
    "    mad_vals = mad_matrix(matrix, dims=1)\n",
    "    lower_bound = median_vals .- threshold .* mad_vals\n",
    "    upper_bound = median_vals .+ threshold .* mad_vals\n",
    "    filtered_matrix = copy(matrix)\n",
    "    \n",
    "    for i in 1:size(matrix, 2)  # iterate over columns\n",
    "        for j in 1:size(matrix, 1)  # iterate over rows\n",
    "            if matrix[j, i] < lower_bound[i] || matrix[j, i] > upper_bound[i]\n",
    "                filtered_matrix[j, i] = median_vals[i]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return filtered_matrix\n",
    "end\n",
    "\n",
    "# Remove outliers from the spectral matrix\n",
    "filtered_spectral_matrix = remove_outliers_using_mad(spectral_matrix)\n",
    "\n",
    "# Calculate the mean spectra after outlier removal\n",
    "mean_spectra_filtered = mean(filtered_spectral_matrix, dims=1)\n",
    "mean_spectra_vector_filtered = vec(mean_spectra_filtered)\n",
    "\n",
    "println(\"Filtered Mean Spectra: \", mean_spectra_vector_filtered)\n",
    "\n",
    "# Compute the difference spectra\n",
    "difference_spectra = mean_spectra_vector - mean_spectra_vector_filtered\n",
    "\n",
    "println(\"Difference Spectra: \", difference_spectra)\n",
    "\n",
    "# Perform the inverse Fourier transform to get the time series of the outliers\n",
    "time_series_outliers = real(ifft(difference_spectra))\n",
    "\n",
    "println(\"Time Series of Outliers: \", time_series_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "p1 = Plots.plot()\n",
    "    \n",
    "for ii in 1:length(f2)\n",
    "    p1 = Plots.plot!(f2[ii], Pden2[ii], lc=:gray, alpha=:0.25, label=\"\")\n",
    "end\n",
    "##==\n",
    "for ii in 1:nrow(RDT_noise)\n",
    "    p1 = Plots.plot!(RDT_noise.Frequency[ii], RDT_noise.Spectra[ii], lc=:lightgrey, alpha=:0.1, label=\"\")\n",
    "end\n",
    "#==#\n",
    "p1 = Plots.plot!(f2[1],  mean_spectra_vector, lw=:5, lc=:yellow, label=\"Mean\")\n",
    "\n",
    "p1 = Plots.plot!(f2[1],  median_spectra_vector, lw=:2, lc=:lightblue, label=\"Median\")\n",
    "\n",
    "##p1 = Plots.plot!(SDT_noise.Freq[1], mad_spectra_vector, lw=:2, lc=:pink, label=\"MAD\")\n",
    "\n",
    "p1 = Plots.plot!(f2[1], mean_spectra_vector_filtered, lw=:2, lc=:blue, label=\"Filtered\")\n",
    "\n",
    "p1_plot = plot(p1, layout=(1,1), size=(1800,800), lw=:0.5, fillrange = 0, fillalpha = 0.05, \n",
    "    xlim=(0.0,0.58), xtickfontsize=12, ytickfontsize=12, xminorticks=12, xlabel=\"Frequency (Hz)\",\n",
    "    yaxis=:log, ylim=(0.000001,10),  ylabel=\"S(f) (m²/Hz)\", legend=:topright, legendfontpointsize=:12, legendtitlefonthalign=:right,\n",
    "    legendtitle=\"Noise floor based on \"*string(nrow(RDT_noise))*\" spectra\", legendtitlefontpointsize=:14,\n",
    "    guidefontsize=:14, framestyle = :box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "    title = Dates.format(records_df.Date[1], \"dd/mm/yy HH:MM\")*\" to \"*Dates.format(records_df.Date[end], \"dd/mm/yy HH:MM\"),\n",
    "    titlefontsizes=:16, leftmargin = 15Plots.mm, bottommargin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n",
    "\n",
    "display(p1_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **********************************************************************************************************************\n",
    "## All below is work in progress\n",
    "# **********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Cross Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## day1 = RDT_df.Date[1]\n",
    "day1_string = Dates.format.(day1, \"yyyy-mm-dd HH:MM\")\n",
    "day2 = RDT_df.Date[end]\n",
    "day2_string = Dates.format.(day2 + Day(1), \"yyyy-mm-dd HH:MM\")\n",
    "\n",
    "println(\"\\nEnter START date <DD/MM/YYYY> between \",day1_string,\" and \",day2_string)\n",
    "flush(stdout)\n",
    "global start_date_str = readline()\n",
    "\n",
    "println(start_date_str)\n",
    "flush(stdout)\n",
    "\n",
    "first_date = DateTime(start_date_str, \"dd/mm/yyyy\")\n",
    "\n",
    "# do rough check that valid date has been entered\n",
    "if (day1 < first_date ) & (first_date < day2) \n",
    "    \n",
    "    # get data for selected day\n",
    "    daily = RDT_df[findall(first_date .<= RDT_df.Date .< (first_date + Day(1))),:];\n",
    "\n",
    "    start_time = daily.Date[1]\n",
    "    dates = [(julian2datetime.(datetime2julian(start_time)) .+ Minute(i*30)) for i in collect(0:1:47)]\n",
    "    date_string = Dates.format.(dates, \"yyyy-mm-dd HH:MM:SS\")\n",
    "\n",
    "    using Tk\n",
    "\n",
    "    w = Toplevel(\"Select Date\", 235, 600)\n",
    "    tcl(\"pack\", \"propagate\", w, false)\n",
    "    f = Frame(w)\n",
    "    pack(f, expand=true, fill=\"both\")\n",
    "\n",
    "    f1 = Frame(f)\n",
    "    lb = Treeview(f1, date_string)\n",
    "    scrollbars_add(f1, lb)\n",
    "    pack(f1,  expand=true, fill=\"both\")\n",
    "\n",
    "    tcl(\"ttk::style\", \"configure\", \"TButton\", foreground=\"blue\", font=\"arial 16 bold\")\n",
    "    b = Button(f, \"Ok\")\n",
    "    pack(b)\n",
    "\n",
    "    bind(b, \"command\") do path\n",
    "\n",
    "        date_choice = get_value(lb)\n",
    "        idx = indexin(date_choice, date_string)\n",
    "        global idx = idx[1]\n",
    "\n",
    "##        println(idx,' ',date_string[idx])\n",
    "\n",
    "    end\n",
    "\n",
    "    record = daily[dates[idx] .<= daily.Date .< dates[idx] + Minute(30),:];\n",
    "    \n",
    "else\n",
    "    \n",
    "    println(\"Invalid selection Try again!\") \n",
    "\n",
    "end\n",
    "\n",
    "title_string = Dates.format(record.Date[1], \"yyyy-mm-dd HH:MM\")\n",
    "println(idx,\" \",record.Date[1],\" \",title_string)\n",
    "flush(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DSP\n",
    "\n",
    "npts = 2048\n",
    "heave = record[1:npts,3]\n",
    "\n",
    "sample_frequency = 1.28\n",
    "nyquist = sample_frequency/2\n",
    "n=div(length(heave), 9)\n",
    "\n",
    "spec1 = periodogram(heave; onesided=eltype(heave)<:Real, nfft=nextfastfft(size(heave))[1], fs=1.28, window=hanning)\n",
    "spec = welch_pgram(heave, n, div(n, 2); onesided=eltype(heave)<:Real, nfft=nextfastfft(n), fs=1.28, window=hanning)      \n",
    "\n",
    "p1 = plot(freq(spec1), power(spec1), lc=:lightblue, lw=:2, z_order=:1, label=\"Periodogram\")\n",
    "p1 = plot!(freq(spec), power(spec), lc=:blue, lw=:2, z_order=:2, label=\"Welch's method\\n\")\n",
    "\n",
    "#spec = mt_pgram(heave; onesided=eltype(heave)<:Real, nfft=nextfastfft(size(heave))[1], fs=1.28, nw=4, ntapers=ceil(2nw)-1, window=dpss(length(heave), nw, ntapers))\n",
    "\n",
    "cps_heave_heave = mt_cross_power_spectra([heave heave]', fs=sample_frequency);\n",
    "\n",
    "p1 = plot!(cps_heave_heave.freq, real.(cps_heave_heave.power[1,1,:]), lc=:red, lw=:2, fillto=:0, fillcolor=:red, fillalpha=:0.125, z_order=:3, label=\"Cross Power Spectra\")\n",
    "            \n",
    "spectral_plot = plot(p1, size=(1200,600), title=title_string,\n",
    "    xlim=(0,nyquist), xtickfontsize=7, xminorticks=5, ylim=(0,maximum(power(spec1)*1.05)), ytickfontsize=8, yminorticks=10,\n",
    "    framestyle = :box,fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    leftmargin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Fourier coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hint came from https://discourse.julialang.org/t/spectral-coherence-in-julia/106144/9 rafael.guerra\n",
    "using DSP\n",
    "\n",
    "\n",
    "function atan2(b,a)    \n",
    "#########################\n",
    "\"\"\"\n",
    "    function to calculate direction from Fourier coefficients a1 and b1\n",
    "    and return result in Radians\n",
    "    \n",
    "    Note: refer to https://en.wikipedia.org/wiki/Atan2\n",
    "    \n",
    "    Calls: Function atan2()\n",
    "    Inputs: b and a \n",
    "    Returns: 0 <= c <= 2π\n",
    "    \n",
    "\"\"\" \n",
    "    len = length(b)\n",
    "    c = zeros(len)\n",
    "    \n",
    "    for i in 1:length(b)\n",
    "\n",
    "        # if both a1 and b1 are 0 then return 0 (to avoid NaN)\n",
    "        if (a[i]!=0) & (b[i]!=0)\n",
    "\n",
    "            c[i] = atan(b[i] / a[i])\n",
    "\n",
    "            if a[i] >= 0\n",
    "\n",
    "                if b[i] >= 0\n",
    "\n",
    "                    c[i] = pi/2 - abs(c[i])\n",
    "\n",
    "                else\n",
    "\n",
    "                    c[i] = pi/2 + abs(c[i])\n",
    "\n",
    "                end            \n",
    "\n",
    "            else\n",
    "\n",
    "                if b[i] >= 0\n",
    "\n",
    "                    c[i] = 3*pi/2  + abs(c[i])\n",
    "\n",
    "                else\n",
    "\n",
    "                    c[i] = 3*pi/2 - abs(c[i])\n",
    "\n",
    "                end\n",
    "\n",
    "            end\n",
    "\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    # return direction in Degrees\n",
    "    return(c)\n",
    "        \n",
    "    end    # atan2()\n",
    "\n",
    "\n",
    "function atan2d(b,a)\n",
    "#########################\n",
    "\"\"\"\n",
    "    function to calculate direction from Fourier coefficients a1 and b1\n",
    "    and return result in Degrees\n",
    "    \n",
    "    Note: refer to https://en.wikipedia.org/wiki/Atan2\n",
    "    \n",
    "    Calls: Function atan2()\n",
    "    Inputs: b and a \n",
    "    Returns: 0 <= c <= 360\n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "    return(rad2deg.(atan2(b,a)))\n",
    "            \n",
    "end\n",
    "\n",
    "\n",
    "sample_frequency = 1.28\n",
    "nyquist = sample_frequency/2\n",
    "\n",
    "npts = 2048 #2304\n",
    "\n",
    "record = 1  #<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "y = npts*record\n",
    "x = y-npts+1\n",
    "\n",
    "heave = RDT_df[1:npts,3]\n",
    "north = RDT_df[1:npts,4]\n",
    "west = -RDT_df[1:npts,5]\n",
    "\n",
    "# Get the cross periodograms\n",
    "cps_heave_heave = mt_cross_power_spectra([heave heave]', fs=sample_frequency);\n",
    "cps_north_north = mt_cross_power_spectra([north north]', fs=sample_frequency);\n",
    "cps_west_west = mt_cross_power_spectra([west west]', fs=sample_frequency);\n",
    "\n",
    "cps_north_heave = mt_cross_power_spectra([north heave]', fs=sample_frequency);\n",
    "cps_west_heave = mt_cross_power_spectra([west heave]', fs=sample_frequency);\n",
    "cps_north_west = mt_cross_power_spectra([north west]', fs=sample_frequency);\n",
    "\n",
    "fhh = cps_heave_heave.freq\n",
    "Chh = real.(cps_heave_heave.power[1,1,:])\n",
    "\n",
    "fnn = cps_north_north.freq\n",
    "Cnn = real.(cps_north_north.power[1,1,:])\n",
    "\n",
    "fww = cps_west_west.freq\n",
    "Cww = real.(cps_west_west.power[1,1,:])\n",
    "\n",
    "fnw = cps_north_west.freq\n",
    "Cnw = real.(cps_north_west.power[1,2,:])\n",
    "\n",
    "fnh = cps_north_heave.freq\n",
    "Qnh = imag.(cps_north_heave.power[1,2,:])\n",
    "\n",
    "fwh = cps_west_heave.freq\n",
    "Qwh = imag.(cps_west_heave.power[1,2,:])\n",
    "\n",
    "title_string = Dates.format(RDT_df[1,:].Date, \"yyyy-mm-dd HH:MM:SS\")\n",
    "\n",
    "p1 =  plot(fhh, Chh, lc=:red, lw=:1, title=\"Chh\")\n",
    "p2 =  plot(fnn, Cnn, lc=:red, lw=:1, title=\"Cnn\")\n",
    "p3 =  plot(fww, Cww, lc=:red, lw=:1, title=\"Cww\")\n",
    "p4 =  plot(fnw, Cnw, lc=:red, lw=:1, title=\"Cnw\")\n",
    "p5 =  plot(fnh, Qnh, lc=:red, lw=:1, title=\"Qhn\")\n",
    "p6 =  plot(fwh, Qwh, lc=:red, lw=:1, title=\"Qhw\")\n",
    "\n",
    "cross_spectral_plot = plot(p1, p2, p3, p4, p5, p6, label=\"\", size=(1600,600), layout=(2,3),\n",
    "    lw=:0.5,\n",
    "    xlim=(0,nyquist), xtickfontsize=7,ytickfontsize=8, xminorticks=5,\n",
    "    plot_title=title_string, titlefontsize=:10,\n",
    "    framestyle = :box,fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    topmargin = 0Plots.mm, leftmargin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n",
    "\n",
    "savefig(\".\\\\\" * \"RDT_file_\"*split(splitdir(infil)[end],\".\")[1] * \"_Cross_spectra.png\")\n",
    "\n",
    "display(cross_spectral_plot)\n",
    "\n",
    "a1 = Qnh ./ ((Cnn .+ Cww) .* Chh) .^ 0.5\n",
    "b1 = -Qwh ./ ((Cnn .+ Cww) .* Chh) .^ 0.5\n",
    "\n",
    "a2 = (Cnn .- Cww) ./ (Cnn .+ Cww)\n",
    "b2 = -2 .* Cnw ./ (Cnn .+ Cww)\n",
    "\n",
    "p1 =  plot(fhh, a1, lc=:green, lw=:1, title=\"a1\")\n",
    "p2 =  plot(fhh, b1, lc=:green, lw=:1, title=\"b1\")\n",
    "p3 =  plot(fhh, a2, lc=:green, lw=:1, title=\"a2\")\n",
    "p4 =  plot(fhh, b2, lc=:green, lw=:1, title=\"b2\")\n",
    "\n",
    "###################################################\n",
    "spectral_coefficients_plot = plot(p1, p2, p3, p4, label=\"\", size=(1600,600), layout=(2,2),\n",
    "    lw=:0.5,\n",
    "    xlim=(0,nyquist), xtickfontsize=7,ytickfontsize=8, xminorticks=5,\n",
    "    titlefontsize=:10,\n",
    "    framestyle = :box,fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    leftmargin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n",
    "\n",
    "savefig(\".\\\\\"*\"RDT_file_\"*split(splitdir(infil)[end],\".\")[1]*\"_Spectral_coefficients.png\")\n",
    "\n",
    "display(spectral_coefficients_plot)\n",
    "\n",
    "\n",
    "theta = atan.(b1,a1)\n",
    "m1 = (a1.^2 .+ b1.^2).^0.5\n",
    "m2 = a2 .* cos.(2 .* theta) .+ b2 .* sin.(2 .* theta)\n",
    "n2 = -a2 .* sin.(2 .* theta) .+ b2 .* cos.(2 .* theta)\n",
    "\n",
    "p1 = plot(fhh, m1, lc=:blue, lw=:1, title=\"m1\")\n",
    "p2 = plot(fhh, m2, lc=:blue, lw=:1, title=\"m2\")\n",
    "p3 = plot(fhh, n2, lc=:blue, lw=:1, title=\"n2\")\n",
    "\n",
    "###################################################\n",
    "centred_Fourier_coefficients_plot = plot(p1, p2, p3, label=\"\", size=(1600,300), layout=(1,3),\n",
    "    lw=:0.5,\n",
    "    xlim=(0,nyquist), xtickfontsize=7,ytickfontsize=8, xminorticks=5,\n",
    "    titlefontsize=:10,\n",
    "    framestyle = :box,fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    leftmargin = 5Plots.mm, rightmargin = 0Plots.mm, bottommargin = 5Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n",
    "\n",
    "savefig(\".\\\\\"*\"RDT_file_\"*split(splitdir(infil)[end],\".\")[1]*\"_centred_Fourier_coefficients.png\")\n",
    "\n",
    "display(centred_Fourier_coefficients_plot)\n",
    "\n",
    "##dirn = mod.(rad2deg.(theta .- pi), 360)\n",
    "dirn = mod.(atan2d(b1, a1) .- 90, 360)\n",
    "spread = rad2deg.((2 .- 2 .* m1).^0.5)\n",
    "\n",
    "w = spread\n",
    "\n",
    "# plot the direction\n",
    "using StatsBase\n",
    "\n",
    "title_string = Dates.format(RDT_df[1,:].Date, \"yyyy-mm-dd HH:MM:SS\")*\" AEST\"\n",
    "\n",
    "weighted_mean = mean(dirn,weights(Chh))\n",
    "fp = fhh[argmax(Chh)]\n",
    "\n",
    "p1 = plot(fhh, dirn, ribbon = w, lw=:1, ls=:dot, c=:blue, fillalpha = 0.25, yflip = false, tickfonthalign=:right,\n",
    "        ylabel=\"Direction (ᵒ)\", yguidefontcolor=:blue, yguidefontrotation=:180, ytickfontcolor=:blue, \n",
    "        yticks = 0:30:360, yminorgrid=:true, yminorticks=:3, ylim=(0,360), label=\"Direction\", titlefontsize=10,\n",
    "        framestyle = :box,fg_legend=:transparent, bg_legend=:transparent, legend=:topleft, xlim=(0,0.64),\n",
    "        grid=:true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, tickfontsize=7, z_order=:1)\n",
    "\n",
    "\n",
    "\n",
    "p1 = hline!([weighted_mean], lc=:blue, ls=:dash, label=\"Avg. Direction = \"*string(round.(weighted_mean; digits=1))*\"ᵒ\")\n",
    "p1 = vline!([fp], lc=:red, ls=:dashdot, label=\"Tp = \"*string(round.(1/fp; digits=1))*\"s (Peak freq. = \"*string(round.(fp; digits=2))*\"Hz)\")\n",
    "\n",
    "# calculate and plot the spectra\n",
    "cps_heave_heave = mt_cross_power_spectra([heave heave]', fs=sample_frequency)\n",
    "\n",
    "n=div(length(heave), 9)\n",
    "spec = welch_pgram(heave, n, div(n, 2); onesided=eltype(heave)<:Real, nfft=nextfastfft(n), fs=1.28, window=hanning)\n",
    "\n",
    "ymax_val = max(maximum(spec.power),maximum(real.(cps_heave_heave.power[1,1,:])))\n",
    "p1 = plot!(twinx(), cps_heave_heave.freq, real.(cps_heave_heave.power[1,1,:]), lc=:red, lw=:1, fillrange = 0, fillcolor=:red, fillalpha = 0.25, label=\"Spectra\", ylabel=\"Spectral Density (m²/Hz.)\", \n",
    "        yguidefontcolor=:red, ytickfontcolor=:red, legend=:topright, xlim=(0,0.64), ylim=(0,ymax_val))\n",
    "\n",
    "p1 = plot!(twinx(), freq(spec), power(spec), lc=:red, lw=:2, ls=:dot, label=\"\\nWelch\", xlim=(0,0.64), ylim=(0,ymax_val))\n",
    "\n",
    "###################################################\n",
    "\n",
    "direction_spectra_plot = plot(p1, size=(1600,800), xtickfontsize=7,ytickfontsize=8, xminorticks=5, title=\"Chh and Direction\", titlefontsize=:10,\n",
    "    framestyle = :box,fg_legend=:transparent, bg_legend=:transparent,\n",
    "    leftmargin = 15Plots.mm, rightmargin = 12Plots.mm, topmargin = 0Plots.mm)\n",
    "\n",
    "savefig(\".\\\\\"*\"RDT_file_\"*split(splitdir(infil)[end],\".\")[1]*\"_Chh_Dir.png\")\n",
    "\n",
    "display(direction_spectra_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dirn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1:aa\n",
    "j = 1:1:361\n",
    "\n",
    "f(i, j) = begin\n",
    "    \n",
    "    max(Chh[i] * (a1[i]*cosd(j-1) + b1[i]*sind(j-1) + a2[i]*cosd((2*j-1)) + b2[j]*sind(2*(j-1))),0)\n",
    "\n",
    "end\n",
    "\n",
    "X = repeat(reshape(i, 1, :), length(j), 1)\n",
    "Y = repeat(j, 1, length(i))\n",
    "Z = map(f, X, Y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tm_tick = range(0,0.64,step=100)\n",
    "ticks = 1:80:aa\n",
    "ticklabels = [string(round(fhh[x], digits=2)) for x in ticks ]\n",
    "\n",
    "p1 = contourf(i, j, f, lw=0.25, lc=:white, c=cgrad(:Spectral,rev=true), levels=50)\n",
    "p1 = contour!(i, j, f, lc=:grey, lw=:0.5)\n",
    "plot(p1, size=(800,800), xticks=(ticks,ticklabels),yticks=0:30:360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function smooth_spectra(Pden_in, sample_frequency)\n",
    "##################################################\n",
    "# smooth the spectra into bands centered on 0.05Hz spacing (i.e. 0:0.005:0.64)\n",
    "    nyquist = sample_frequency/2\n",
    "\n",
    "    freq_in = range(0, stop=nyquist, length=length(Pden_in))\n",
    "\n",
    "    freq_out = [0.0]\n",
    "    Pden_smoothed = [mean(Pden_in[1:8])]\n",
    "\n",
    "    i = 9\n",
    "    while i <= length(Pden_in)\n",
    "\n",
    "        push!(freq_out,freq_in[i+8])\n",
    "\n",
    "        if i < length(Pden_in)-16\n",
    "\n",
    "            push!(Pden_smoothed, mean(Pden_in[i:i+16]))\n",
    "\n",
    "        end\n",
    "\n",
    "        i+=16\n",
    "\n",
    "    end\n",
    "\n",
    "    push!(Pden_smoothed, mean(Pden_in[end-8:end]))\n",
    "            \n",
    "    return (freq_out, Pden_smoothed)\n",
    "        \n",
    "end    # smooth_spectra()\n",
    "\n",
    "\n",
    "function get_Fourier_coefficients(heave, north, west)\n",
    "#####################################################    \n",
    "    # Get the cross periodograms\n",
    "    cps_heave_heave = mt_cross_power_spectra([heave heave]', fs=sample_frequency);\n",
    "    cps_north_north = mt_cross_power_spectra([north north]', fs=sample_frequency);\n",
    "    cps_west_west = mt_cross_power_spectra([west west]', fs=sample_frequency);\n",
    "\n",
    "    cps_north_heave = mt_cross_power_spectra([north heave]', fs=sample_frequency);\n",
    "    cps_west_heave = mt_cross_power_spectra([west heave]', fs=sample_frequency);\n",
    "    cps_north_west = mt_cross_power_spectra([north west]', fs=sample_frequency);\n",
    "\n",
    "##    fhh = cps_heave_heave.freq\n",
    "    fhh, Chh = smooth_spectra(real.(cps_heave_heave.power[1,1,:]), sample_frequency)\n",
    "\n",
    "    #fnn = cps_north_north.freq\n",
    "    fhh, Cnn = smooth_spectra(real.(cps_north_north.power[1,1,:]), sample_frequency)\n",
    "\n",
    "    #fww = cps_west_west.freq\n",
    "    fhh, Cww = smooth_spectra(real.(cps_west_west.power[1,1,:]), sample_frequency)\n",
    "\n",
    "    #fnw = cps_north_west.freq\n",
    "    fhh, Cnw = smooth_spectra(real.(cps_north_west.power[1,2,:]), sample_frequency)\n",
    "\n",
    "    #fnh = cps_north_heave.freq\n",
    "    fhh, Qnh = smooth_spectra(imag.(cps_north_heave.power[1,2,:]), sample_frequency)\n",
    "\n",
    "    #fwh = cps_west_heave.freq\n",
    "    fhh, Qwh = smooth_spectra(imag.(cps_west_heave.power[1,2,:]), sample_frequency)\n",
    "\n",
    "    a1 = Qnh ./ ((Cnn .+ Cww) .* Chh) .^ 0.5\n",
    "    b1 = -Qwh ./ ((Cnn .+ Cww) .* Chh) .^ 0.5\n",
    "\n",
    "    a2 = (Cnn .- Cww) ./ (Cnn .+ Cww)\n",
    "    b2 = -2 .* Cnw ./ (Cnn .+ Cww)\n",
    "    \n",
    "    return(fhh, Chh, a1, b1, a2, b2)\n",
    "    \n",
    "end    # get_Fourier_coefficients()\n",
    "\n",
    "\n",
    "function get_displacements(arry)\n",
    "#####################################\n",
    "    \n",
    "    displacements = []\n",
    "\n",
    "    if length(arry[1]) == 3\n",
    "    \n",
    "        for i in arry\n",
    "            append!(displacements,parse(Int, SubString.(i, 1, 1), base=16)*16^2 + parse(Int, SubString.(i, 2, 2), base=16)*16^1 + parse(Int, SubString.(i, 3, 3), base=16)*16^0)\n",
    "        end\n",
    "        \n",
    "    else\n",
    "        \n",
    "        for i in arry\n",
    "            append!(displacements,parse(Int, SubString.(i, 1, 1), base=16)*16^1 + parse(Int, SubString.(i, 2, 2), base=16)*16^0)\n",
    "        end\n",
    "        \n",
    "    end\n",
    "\n",
    "    displacements[findall(>=(2048), displacements)] = 2048 .- displacements[findall(>=(2048), displacements)];\n",
    "    \n",
    "    return(displacements./100)\n",
    "    \n",
    "end     # get_displacements()\n",
    "\n",
    "\n",
    "function get_HNW(infil)\n",
    "#####################################\n",
    "        \n",
    "    global df = DataFrame(CSV.File(infil,header=0, delim=\",\", types=String));\n",
    "\n",
    "    # Calculate sequence numbers\n",
    "    arry = SubString.(df.Column1, 3, 4)\n",
    "\n",
    "    global sequence = []\n",
    "\n",
    "    for i in arry\n",
    "        append!(sequence,parse(Int, SubString.(i, 1, 1), base=16)*16^1 + parse(Int, SubString.(i, 2, 2), base=16)*16^0)\n",
    "    end\n",
    "\n",
    "    arry = SubString.(df.Column3, 1, 3);\n",
    "    heave = get_displacements(arry);\n",
    "\n",
    "    # Calculate north WSEs\n",
    "    arry = SubString.(df.Column3, 4, ) .* SubString.(df.Column4, 1, 2)\n",
    "    north = get_displacements(arry);\n",
    "\n",
    "    # Calculate north WSEs\n",
    "    arry = SubString.(df.Column4, 3, 4) .* SubString.(df.Column5, 1, 1)\n",
    "    west = get_displacements(arry);\n",
    "\n",
    "    return(heave, north, west)\n",
    "\n",
    "    end    # get_HNW()\n",
    "\n",
    "\n",
    "function get_spec_dir(displacement_df, total)\n",
    "\n",
    "    Chh = displacement_df.Chh[total]\n",
    "    a1 = displacement_df.a1[total]\n",
    "    b1 = displacement_df.b1[total] \n",
    "    a2 = displacement_df.a2[total] \n",
    "    b2 = displacement_df.b2[total]\n",
    "    time_string[] = displacement_df.Time_string[total]\n",
    "\n",
    "    aa = length(Chh) # Number of spectral points\n",
    "\n",
    "    r = 1:3:aa\n",
    "    ρ = r ./ (aa/nyquist) \n",
    "\n",
    "    θ = 0:pi/180:2pi\n",
    "\n",
    "#    mat =  []\n",
    "\n",
    "    mat = [Chh[j] * (a1[j]*cos(i) + b1[j]*sin(i) + a2[j]*cos(2i) + b2[j]*sin(2i)) for i in θ, j in r]\n",
    "\n",
    "    mat[mat .< 0] .= 0\n",
    "    \n",
    "    return(θ, ρ, mat, time_string)\n",
    "    \n",
    "end    # get_spec_dir()\n",
    "\n",
    "using CairoMakie\n",
    "using DSP\n",
    "using GLMakie\n",
    "using Statistics\n",
    "\n",
    "using CSV\n",
    "#using CurveFit\n",
    "using Dates, DataFrames\n",
    "#, Distributions, DSP\n",
    "#using Gtk\n",
    "#using LaTeXStrings\n",
    "using NativeFileDialog\n",
    "using Plots\n",
    "using Printf\n",
    "#using Tk\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "# Select a Datawell daily .RDT file\n",
    "infil = pick_file(\"C:\\\\\", filterlist=\"*RDT\");\n",
    "##infil = \"G:\\\\Wave_data\\\\Card Data\\\\mooloolaba\\\\Mooloolaba_WR_2018-2020\\\\07039ALO.RDT\"\n",
    "println(\"Selected \",infil)\n",
    "\n",
    "#Change the type-interpretation of the binary file data to unsigned integer\n",
    "println(\"Reading BINARY data from \",infil)\n",
    "data_array = reinterpret(UInt8, read(infil));\n",
    "\n",
    "date_time_list = []\n",
    "north_hex_values = []\n",
    "\n",
    "ii = 1\n",
    "RDT_df = DataFrame([[],[],[],[],[],[]], [\"Date\", \"UTC\", \"Heave\", \"North\", \"West\", \"GPS_error\"])\n",
    "\n",
    "# Convert df column types from 'Any' to their proper type\n",
    "RDT_df.Date = map(DateTime, RDT_df.Date);\n",
    "RDT_df.UTC = map(DateTime, RDT_df.UTC);\n",
    "RDT_df.Heave = map(Float64, RDT_df.Heave);\n",
    "RDT_df.North = map(Float64, RDT_df.North);\n",
    "RDT_df.West = map(Float64, RDT_df.West);\n",
    "RDT_df.GPS_error = map(Int32, RDT_df.GPS_error);\n",
    " \n",
    "\n",
    "println(\"Decoding RDT data now\")\n",
    "flush(stdout)\n",
    "\n",
    "while ii < length(data_array)\n",
    "    \n",
    "    start_of_message = string(data_array[ii], base=16, pad=2)\n",
    "    message_id = string(data_array[ii+1], base=16, pad=2)\n",
    "    message_length = parse(Int, string(data_array[ii+2], base=16, pad=2) * string(data_array[ii+3], base=16, pad=2), base= 16)\n",
    "    check_sum1 = string(data_array[ii+4], base=16, pad=2)    \n",
    "\n",
    "    yr = parse(Int,(string(data_array[ii+5], base=16) * string(data_array[ii+6], base=16, pad=2)), base= 16)\n",
    "\n",
    "    month = parse(Int, string(data_array[ii+7], base=16, pad=2), base= 16)\n",
    "    day = parse(Int, string(data_array[ii+8], base=16, pad=2), base= 16)\n",
    "    hour = parse(Int, string(data_array[ii+9], base=16, pad=2), base= 16)\n",
    "    minute = parse(Int, string(data_array[ii+10], base=16, pad=2), base= 16)\n",
    "\n",
    "    # Calculate the sample rate\n",
    "    sample_rate_hex = parse(UInt32,\"0x\"* string(data_array[ii+11], base=16, pad=2) * string(data_array[ii+12], base=16, pad=2) \n",
    "        * string(data_array[ii+13], base=16, pad=2) * string(data_array[ii+14], base=16, pad=2))\n",
    "    sample_rate = reinterpret(Float32, parse(UInt32, \"0x\"*string(sample_rate_hex, base=16)))\n",
    "\n",
    "    utc = DateTime(yr,month,day,hour,minute)\n",
    "    aest = utc + Hour(10)\n",
    "    push!(date_time_list,aest)\n",
    "\n",
    "    if (sample_rate != 1.28f0) \n",
    "\n",
    "        println(\"Error: Sample rate not 1.28 Hz - Program terminated!\")\n",
    "        quit()\n",
    "\n",
    "    end\n",
    "\n",
    "    rows = (message_length-10)/6\n",
    "    \n",
    "    for jj in 15:6:message_length\n",
    "    \n",
    "        # generate an array of dates at spacing equal to sample_rate\n",
    "        aest = utc .+ Hour(10)\n",
    "\n",
    "        heave = []\n",
    "        north = []\n",
    "        west = []\n",
    "\n",
    "        # Calculate the displacements\n",
    "        heave_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj], base=16, pad=2) * string(data_array[ii+jj+1], base=16, pad=2))\n",
    "        heave = reinterpret(Int16, parse(UInt16, \"0x\"*string(heave_hex, base=16))) / 100\n",
    "\n",
    "        global north_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj+2], base=16, pad=2) * string(data_array[ii+jj+3], base=16, pad=2))\n",
    "        north = reinterpret(Int16, parse(UInt16, \"0x\"*string(north_hex, base=16))) / 100\n",
    "\n",
    "        west_hex = parse(UInt16,\"0x\"* string(data_array[ii+jj+4], base=16, pad=2) * string(data_array[ii+jj+5], base=16, pad=2))\n",
    "        west = reinterpret(Int16, parse(UInt16, \"0x\"*string(west_hex, base=16))) / 100\n",
    "\n",
    "        push!(RDT_df,(utc .+ Hour(10), utc, heave, north, west, parse(Int, last(string(north_hex, base=2, pad=16),1))))\n",
    "         \n",
    "        # increment the record time\n",
    "        utc = utc + Microsecond.(1/sample_rate * 1000000)\n",
    "\n",
    "    end\n",
    "    \n",
    "    check_sum2 = string(data_array[message_length+1], base=16, pad=2)\n",
    "    print(\".\")\n",
    "    flush(stdout)\n",
    "#==\n",
    "    println(\"Checksum = \",check_sum2)\n",
    "    println(\"_________________________________________\")\n",
    "==#\n",
    "    \n",
    "    ii += message_length + 6\n",
    "    \n",
    "end\n",
    "\n",
    "# print number of GPS errors if they exist\n",
    "gps_error_number = sum(RDT_df.GPS_error)\n",
    "if gps_error_number > 0\n",
    "    global gps_error_locations = findall(RDT_df.GPS_error .> 0)\n",
    "    println(\"\\nAlert: there were \",gps_error_number,\" errors in this record!\\n\")\n",
    "    flush(stdout)\n",
    "end\n",
    "\n",
    "const sample_frequency = 1.28\n",
    "nyquist = sample_frequency/2\n",
    "\n",
    "# Build daily df containing spectral data\n",
    "record = 1\n",
    "start_val = DateTime(Date(RDT_df.Date[1]))\n",
    "end_val = start_val + Minute(30)\n",
    "    \n",
    "# build df containing displacements and Fourier coefficient for selected day\n",
    "displacement_df = DataFrame(Time_string = [], Heave = [], North = [], West = [], fhh = [], Chh = [], a1 = [], b1 = [], a2 = [], b2 = [], mat = [])\n",
    "\n",
    "println(\"\\nProcessing each 30-minute record:\")\n",
    "\n",
    "while record <= (round((RDT_df.Date[end] - RDT_df.Date[1]).value * 0.001 / 1800))\n",
    "        \n",
    "    if (mod(record,10) == 0)\n",
    "        print(string(record))\n",
    "    else\n",
    "        print(\".\")\n",
    "    end\n",
    "    \n",
    "#    try\n",
    "        # find all records for a 30-minute record\n",
    "        temp_df = RDT_df[start_val .<= RDT_df.UTC .< end_val,:]\n",
    "        heave, north, west = temp_df.Heave, temp_df.North, temp_df.West\n",
    "            \n",
    "        # calculate Fourier coefficients\n",
    "        fhh, Chh, a1, b1, a2, b2 = get_Fourier_coefficients(temp_df.Heave, temp_df.North, temp_df.West)\n",
    "        \n",
    "        aa = length(Chh) # Number of spectral points\n",
    "        \n",
    "        r = 1:6:aa\n",
    "        global ρ = r ./ (aa/nyquist) \n",
    "\n",
    "        global θ = 0:pi/180:2pi        \n",
    "\n",
    "        # populate a matrix of spectral surface values\n",
    "        mat = [Chh[r1] * (a1[r1]*cos.(θ) + b1[r1]*sin.(θ) + a2[r1]*cos.(2θ) + b2[r1]*sin.(2θ)) for r1 in r]\n",
    "                    \n",
    "        mat = hvcat(size(mat,1),mat...)\n",
    "\n",
    "        # set any values less than zero to zero\n",
    "        mat[mat .< 0] .= 0\n",
    "        \n",
    "        time_string = Dates.format(start_val, \"dd/mm/yyyy HH:MM\")\n",
    "\n",
    "        # add spectral data to plot df\n",
    "        push!(displacement_df, (time_string, heave, north, west, fhh, Chh, a1, b1, a2, b2, mat));\n",
    "            \n",
    "        record += 1\n",
    "        start_val = end_val\n",
    "        end_val += Minute(30)\n",
    "#==\n",
    "    catch\n",
    "        \n",
    "        println(\"Error\")\n",
    "        break\n",
    "        \n",
    "    end\n",
    "==#    \n",
    "end\n",
    "\n",
    "println(\"\\nPlotting 30-minute records now\")\n",
    "flush(stdout)\n",
    "\n",
    "# get the highest energy value for the day\n",
    "# this sets scaling of plots                    \n",
    "spec_max = maximum(maximum.(displacement_df.mat))\n",
    "                    \n",
    "println(\"Maximum spectra for day = \",round(spec_max, digits=2),\"m²/Hz.\")\n",
    "                    \n",
    "# declare the Observables\n",
    "inc = Observable(1)\n",
    "time_string = Observable(displacement_df[inc[],:].Time_string)\n",
    "mat = Observable(Float64.(displacement_df[inc[],:].mat))\n",
    "fhh_L = Observable(Int(round(length(displacement_df.Chh[1]) / 6)))\n",
    "        \n",
    "fig = CairoMakie.Figure(size=(800, 850))\n",
    "\n",
    "# draw the polar axis\n",
    "ax = CairoMakie.PolarAxis(fig[1, 1],\n",
    "    thetaticklabelsize = 15,  \n",
    "    rlimits=(0,0.6), rticklabelsize=15, rticks=0:0.2:0.6, rgridwidth=0.5, rtickangle=180, rminorgridvisible=true, rminorgridstyle=:dot,\n",
    "    theta_0=-pi/2, thetagridwidth=0.5, thetaminorgridvisible=true, thetaminorgridstyle=:dot, thetaminorticks=IntervalsBetween(3), \n",
    "    direction=-1, width=630, height=610, title=time_string, titlesize=24,\n",
    "    )\n",
    "\n",
    "# Set plotting values\n",
    "cmap = Reverse(:ocean)\n",
    "levels = round(spec_max/100, digits=2):round(spec_max/20, digits=2):round(spec_max, digits=2)\n",
    "θ = 0:pi/180:2pi\n",
    "ρ = range(0, stop=1.28, length=fhh_L[])\n",
    "\n",
    "# do contour plot\n",
    "c1 = CairoMakie.contourf!(ax, θ, ρ, mat, colormap=cmap, levels=levels)\n",
    "c1 = CairoMakie.contour!(ax, θ, ρ, mat, colormap=cmap, levels=levels)\n",
    "                    \n",
    "ax = CairoMakie.Colorbar(fig[2, 1], limits=(0, round(spec_max, digits=1, RoundUp)), label=\"Spectral Density (m²/Hz.)\", labelsize=:20, \n",
    "            width=500, height=30, vertical=false, flipaxis=false, colormap=cmap)  \n",
    "display(fig) \n",
    "\n",
    "# update the Observables\n",
    "for i in 1:nrow(displacement_df)\n",
    "    \n",
    "    inc = i\n",
    "    time_string[] = displacement_df[inc[],:].Time_string\n",
    "    \n",
    "    try\n",
    "        mat[] = Float64.(displacement_df.mat[inc[]])\n",
    "    catch\n",
    "        break\n",
    "    end\n",
    "    \n",
    "    sleep(0.3)\n",
    "    yield()\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\007\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using WAV\n",
    "\n",
    "y, fs = wavread(\"foo.wav\")\n",
    "\n",
    "wavplay(y, fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
